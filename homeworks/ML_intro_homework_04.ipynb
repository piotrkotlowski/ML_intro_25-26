{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Zadanie: Implementacja regresji logistycznej od podstaw\n",
        "\n",
        "Twoim zadaniem jest napisanie klasy `LogisticRegression` w języku **Python**,\n",
        "używając **wyłącznie biblioteki NumPy**.\n",
        "\n",
        "---\n",
        "\n",
        "## Wymagania funkcjonalne\n",
        "\n",
        "### 1. Inicjalizacja (`__init__`)\n",
        "\n",
        "Konstruktor klasy powinien:\n",
        "- przyjmować parametry hiperparametryczne:\n",
        "  - `learning_rate` — współczynnik uczenia\n",
        "  - `n_iters` — liczba iteracji (epok)\n",
        "- inicjalizować wagi i bias (np. zerami)\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Obsługa dowolnej liczby cech\n",
        "\n",
        "Model musi:\n",
        "- automatycznie dopasować rozmiar wektora wag do liczby kolumn\n",
        "  w macierzy cech \\( X \\)\n",
        "- działać poprawnie dla dowolnej liczby cech wejściowych\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Metoda `fit(X, y)`\n",
        "\n",
        "Metoda służy do trenowania modelu przy użyciu algorytmu\n",
        "**Gradient Descent (Spadek Gradientu)**.\n",
        "\n",
        "Wymagania:\n",
        "- iteracyjna aktualizacja wag i biasu\n",
        "- liczba iteracji równa `n_iters`\n",
        "- użycie pochodnych funkcji kosztu (Log Loss)\n",
        "- po zakończeniu treningu wypisanie w konsoli znalezionych parametrów, np.:\n",
        "\n"
      ],
      "metadata": {
        "id": "4h36YU85MbNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### 4. Metoda `predict_proba(X)`\n",
        "\n",
        "- zwraca **prawdopodobieństwo** przynależności do klasy pozytywnej  \n",
        "- wartości z przedziału [0, 1]  \n",
        "- wykorzystuje funkcję sigmoidalną  \n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Metoda `predict(X)`\n",
        "\n",
        "- zwraca etykiety klas: `0` lub `1`  \n",
        "- stosuje próg decyzyjny (threshold)  \n",
        "\n",
        "Reguła decyzyjna:\n",
        "\n",
        "$$\n",
        "\\hat{y} = 1 \\quad \\text{jeśli } P(y = 1) > 0.5\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{y} = 0 \\quad \\text{w przeciwnym razie}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## Część teoretyczna: Gradient Descent (Spadek Gradientu)\n",
        "\n",
        "### Czym jest Gradient Descent?\n",
        "\n",
        "Gradient Descent to **iteracyjny algorytm optymalizacyjny**,  \n",
        "którego celem jest znalezienie minimum funkcji kosztu  \n",
        "(w regresji logistycznej: **Log Loss**).\n",
        "\n",
        "---\n",
        "\n",
        "### Intuicja\n",
        "\n",
        "Wyobraź sobie, że:\n",
        "- stoisz na zboczu góry  \n",
        "- panuje gęsta mgła  \n",
        "- chcesz zejść do najniższego punktu doliny  \n",
        "\n",
        "Nie widzisz celu, ale:\n",
        "- czujesz nachylenie terenu pod stopami  \n",
        "\n",
        "---\n",
        "\n",
        "### Gradient\n",
        "\n",
        "Gradient to:\n",
        "- wektor wskazujący kierunek **największego wzrostu**\n",
        "funkcji kosztu  \n",
        "\n",
        "---\n",
        "\n",
        "### Spadek\n",
        "\n",
        "Aby zmniejszyć błąd:\n",
        "- poruszasz się w **przeciwnym kierunku** do gradientu  \n",
        "\n",
        "---\n",
        "\n",
        "### Learning Rate (alpha)\n",
        "\n",
        "`alpha` określa **wielkość kroku** w każdej iteracji:\n",
        "\n",
        "- zbyt mały → bardzo wolna nauka  \n",
        "- zbyt duży → ryzyko przeskoczenia minimum  \n",
        "\n",
        "---\n",
        "\n",
        "### Gradient w regresji logistycznej\n",
        "\n",
        "W regresji logistycznej:\n",
        "- obliczamy pochodne funkcji kosztu względem wag `w_i`\n",
        "  oraz biasu `b`\n",
        "- aktualizujemy parametry tak, aby **zmniejszyć błąd klasyfikacji**\n",
        "\n",
        "Reguła aktualizacji:\n",
        "\n",
        "$$\n",
        "w = w - \\alpha \\cdot \\nabla J(w)\n",
        "$$\n"
      ],
      "metadata": {
        "id": "OrOlYI8uNCaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Wzór na Log Loss\n",
        "\n",
        "Dla pojedynczej próbki:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(y, \\hat{y}) =\n",
        "- \\left(\n",
        "y \\cdot \\log(\\hat{y})\n",
        "+ (1 - y) \\cdot \\log(1 - \\hat{y})\n",
        "\\right)\n",
        "$$\n",
        "\n",
        "gdzie:\n",
        "- `y` — prawdziwa etykieta (0 lub 1)\n",
        "- `ŷ` — przewidywane prawdopodobieństwo klasy 1\n",
        "\n",
        "---\n",
        "\n",
        "### Log Loss dla całego zbioru danych\n",
        "\n",
        "Dla `N` próbek:\n",
        "\n",
        "$$\n",
        "J = -\\frac{1}{N}\n",
        "\\sum_{i=1}^{N}\n",
        "\\left[\n",
        "y_i \\cdot \\log(\\hat{y}_i)\n",
        "+ (1 - y_i) \\cdot \\log(1 - \\hat{y}_i)\n",
        "\\right]\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### Intuicja działania Log Loss\n",
        "\n",
        "- jeśli model jest **pewny i ma rację** → strata bliska 0  \n",
        "- jeśli model jest **pewny i się myli** → strata bardzo duża  \n",
        "- funkcja jest **gładka i różniczkowalna**,  \n",
        "  co umożliwia zastosowanie Gradient Descent\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "3u6l9MQcONlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    # TODO: Zaimplementuj funkcję 1 / (1 + e^-x)\n",
        "    pass\n",
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.001, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # 1. Pobierz liczbę próbek (n_samples) i cech (n_features) z X\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # 2. Zainicjalizuj parametry\n",
        "        # self.weights =\n",
        "        # self.bias =\n",
        "\n",
        "        # 3. Pętla uczenia (Gradient Descent)\n",
        "        for _ in range(self.n_iters):\n",
        "\n",
        "            # Krok A: Model liniowy (z = wx + b)\n",
        "            # linear_model =\n",
        "\n",
        "            # Krok B: Funkcja aktywacji (predykcja prawdopodobieństwa)\n",
        "            # y_predicted =\n",
        "\n",
        "            # Krok C: Obliczenie gradientów (pochodnych)\n",
        "            # dw =\n",
        "            # db =\n",
        "\n",
        "            # Krok D: Aktualizacja parametrów\n",
        "            # self.weights -=\n",
        "            # self.bias -=\n",
        "            pass\n",
        "        # Na koniec wypisz znalezione parametry\n",
        "        print(f\"Trening zakończony. Wagi: {self.weights}, Bias: {self.bias}\")\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        # 1. Oblicz model liniowy: z = X * w + b\n",
        "        # 2. Zwróć wynik funkcji sigmoid(z)\n",
        "        pass\n",
        "\n",
        "    def predict(self, X):\n",
        "        # 1. Pobierz prawdopodobieństwa z predict_proba(X)\n",
        "        # 2. Zwróć listę/tablicę: 1 jeśli prob > 0.5, w przeciwnym razie 0\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "K0vpxeSrMmKV",
        "outputId": "bbafecb3-4a0e-4bf8-f385-4b926a9d750b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'for' statement on line 23 (ipython-input-1560955751.py, line 40)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1560955751.py\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    print(f\"Trening zakończony. Wagi: {self.weights}, Bias: {self.bias}\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dla ambitnch zaimplementować drzewko decyzyjne od zera."
      ],
      "metadata": {
        "id": "NPWjCm5uhMUr"
      }
    }
  ]
}